{"version":3,"sources":["webpack://[name]/webpack/bootstrap","webpack://[name]/./esm/ext/lz-aggregation-tests.js","webpack://[name]/./esm/data/adapters.js","webpack://[name]/external \"raremetal\""],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","install","LocusZoom","BaseAdapter","Adapters","ConnectorSource","AggregationTestSource","state","chain","fields","required_info","aggregation_tests","header","aggregation_genoset_id","genoset_id","aggregation_genoset_build","genoset_build","aggregation_phenoset_id","phenoset_id","aggregation_pheno","pheno","aggregation_calcs","calcs","mask_data","masks","aggregation_masks","aggregation_mask_ids","map","item","this","url","getURL","JSON","stringify","chrom","chr","start","stop","end","genotypeDataset","phenotypeDataset","phenotype","samples","genomeBuild","body","getCacheKey","fetch","method","headers","then","response","ok","Error","statusText","text","resp","json","parse","error","records","groups","variants","filter","groupType","parsed","parsePortalJSON","byMask","keys","length","results","PortalTestRunner","toJSON","res","mask_id_to_desc","reduce","acc","val","description","data","forEach","group","mask_name","mask","catch","e","console","add","config","from","super","arguments","parseInit","_from","discrete","constructor","SOURCE_NAME","Promise","resolve","REGEX_EPACTS","RegExp","one_variant","match","variant","chromosome","position","ref_allele","ref_allele_freq","altFreq","log_pvalue","Math","log10","pvalue","sort","a","b","aggregation_source_id","_source_name_mapping","gene_source_id","aggregationData","genesData","groupedAggregation","result","push","gene","gene_id","gene_name","tests","aggregation_best_pvalue","min","apply","use","validateBuildSource","class_name","build","source","includes","_enableCache","_cachedKey","_cache_pos_start","_cache_pos_end","__dependentSource","params","cache_pos_chr","req","cacheKey","_cachedResponse","fetchRequest","Array","isArray","N","every","record","j","outnames","trans","fieldFound","k","output_record","v","source_id","normalizeResponse","standardized","annotateData","extractFields","one_source_body","combineChainBody","new_body","preGetData","pre","getRequest","parseResponse","BaseApiAdapter","AssociationLZ","id_field","x","unshift","analysis","LDServer","join","dataFields","id","position_field","pvalue_field","_names_","names","nameMatch","arr","regexes","regex","id_match","obj","isrefvarin","isrefvarout","ldin","ldout","refVar","findRequestedFields","ldrefvar","findMergeFields","columns","pval_field","cmp","test","extremeVal","extremeIdx","findExtremeValue","original","pos","ref","alt","refVar_formatted","genome_build","ld_source","population","ld_pop","refVar_raw","getRefvar","encodeURIComponent","base","_","reqFields","corrField","rsquare","left","right","lfield","rfield","position2","leftJoin","refvar","idfield","outrefname","outldname","tagRefVariant","combined","chainRequests","payload","concat","next","GwasCatalogLZ","build_option","default_source","posMatch","find","decider_out","indexOf","n_matches","fn","outn","chainNames","catNames","GeneLZ","GeneConstraintLZ","unique_gene_names","query","replace","err","alias","constraint","toString","parseFloat","toFixed","RecombLZ","StaticSource","_data","PheWASLZ","sources","specified_ids","_getRequiredSources","chain_source_id","raremetal"],"mappings":";mCACE,IAAIA,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUC,QAGnC,IAAIC,EAASJ,EAAiBE,GAAY,CACzCG,EAAGH,EACHI,GAAG,EACHH,QAAS,IAUV,OANAI,EAAQL,GAAUM,KAAKJ,EAAOD,QAASC,EAAQA,EAAOD,QAASF,GAG/DG,EAAOE,GAAI,EAGJF,EAAOD,QA0Df,OArDAF,EAAoBQ,EAAIF,EAGxBN,EAAoBS,EAAIV,EAGxBC,EAAoBU,EAAI,SAASR,EAASS,EAAMC,GAC3CZ,EAAoBa,EAAEX,EAASS,IAClCG,OAAOC,eAAeb,EAASS,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEZ,EAAoBkB,EAAI,SAAShB,GACX,oBAAXiB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAeb,EAASiB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAeb,EAAS,aAAc,CAAEmB,OAAO,KAQvDrB,EAAoBsB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQrB,EAAoBqB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFA1B,EAAoBkB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOrB,EAAoBU,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRzB,EAAoB6B,EAAI,SAAS1B,GAChC,IAAIS,EAAST,GAAUA,EAAOqB,WAC7B,WAAwB,OAAOrB,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAH,EAAoBU,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRZ,EAAoBa,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG/B,EAAoBkC,EAAI,GAIjBlC,EAAoBA,EAAoBmC,EAAI,I,kCClFrD,yBAkBA,SAASC,EAASC,GAQd,MAAMC,EAAcD,EAAUE,SAAStB,IAAI,eACrCuB,EAAkBH,EAAUE,SAAStB,IAAI,mBAE/C,MAAMwB,UAA8B,iBAChC,OAAOC,EAAOC,EAAOC,GAIjB,MAAMC,EAAgBH,EAAMI,mBAAqB,GAE5CH,EAAMI,SACPJ,EAAMI,OAAS,IAGnBJ,EAAMI,OAAOC,uBAAyBH,EAAcI,YAAc,KAClEN,EAAMI,OAAOG,0BAA4BL,EAAcM,eAAiB,KACxER,EAAMI,OAAOK,wBAA0BP,EAAcQ,aAAe,KACpEV,EAAMI,OAAOO,kBAAoBT,EAAcU,OAAS,KACxDZ,EAAMI,OAAOS,kBAAoBX,EAAcY,OAAS,GACxD,MAAMC,EAAYb,EAAcc,OAAS,GAKzC,OAJAhB,EAAMI,OAAOa,kBAAoBF,EACjCf,EAAMI,OAAOc,qBAAuBH,EAAUI,KAAI,SAAUC,GACxD,OAAOA,EAAKpD,QAETqD,KAAKC,IAGhB,YAAYvB,EAAOC,EAAOC,GAEtB,OADAoB,KAAKE,OAAOxB,EAAOC,EAAOC,GACnBuB,KAAKC,UAAU,CAClBC,MAAO3B,EAAM4B,IACbC,MAAO7B,EAAM6B,MACbC,KAAM9B,EAAM+B,IACZC,gBAAiB/B,EAAMI,OAAOC,uBAC9B2B,iBAAkBhC,EAAMI,OAAOK,wBAC/BwB,UAAWjC,EAAMI,OAAOO,kBACxBuB,QAAS,MACTC,YAAanC,EAAMI,OAAOG,0BAC1BS,MAAOhB,EAAMI,OAAOc,uBAI5B,aAAanB,EAAOC,EAAOC,GACvB,MAAMqB,EAAMD,KAAKE,OAAOxB,EAAOC,EAAOC,GAChCmC,EAAOf,KAAKgB,YAAYtC,EAAOC,EAAOC,GAK5C,OAAOqC,MAAMhB,EAAK,CAACiB,OAAQ,OAAQH,KAAMA,EAAMI,QAJ/B,CACZ,eAAgB,sBAG8CC,KAAMC,IACpE,IAAKA,EAASC,GACV,MAAM,IAAIC,MAAMF,EAASG,YAE7B,OAAOH,EAASI,SACjBL,MAAK,SAAUM,GACd,MAAMC,EAAsB,iBAARD,EAAmBvB,KAAKyB,MAAMF,GAAQA,EAC1D,GAAIC,EAAKE,MAIL,MAAM,IAAIN,MAAMI,EAAKE,OAEzB,OAAOF,KAIf,aAAaG,EAASnD,GASlB,IAAKmD,EAAQC,OACT,MAAO,CAAEA,OAAQ,GAAIC,SAAU,IAGnCF,EAAQC,OAASD,EAAQC,OAAOE,QAAO,SAAUlC,GAC7C,MAA0B,SAAnBA,EAAKmC,aAGhB,MAAMC,EAAS,UAAQC,gBAAgBN,GACvC,IAAIC,EAASI,EAAO,GACpB,MAAMH,EAAWG,EAAO,GAGxBJ,EAASA,EAAOM,OAAO1D,EAAMI,OAAOc,sBAGpC,MAAMJ,EAAQd,EAAMI,OAAOS,kBAC3B,IAAKC,GAAuC,IAA9B3C,OAAOwF,KAAK7C,GAAO8C,OAE7B,MAAO,CAAEP,SAAU,GAAID,OAAQ,GAAIS,QAAS,IAIhD,OAFe,IAAI,UAAQC,iBAAiBV,EAAQC,EAAUvC,GAEhDiD,SACTtB,MAAK,SAAUuB,GAGZ,MAAMC,EAAkBjE,EAAMI,OAAOa,kBAAkBiD,QAAO,SAAUC,EAAKC,GAEzE,OADAD,EAAIC,EAAIpG,MAAQoG,EAAIC,YACbF,IACR,IAIH,OAHAH,EAAIM,KAAKlB,OAAOmB,SAAQ,SAAUC,GAC9BA,EAAMC,UAAYR,EAAgBO,EAAME,SAErCV,EAAIM,QAEdK,OAAM,SAAUC,GAEb,MADAC,QAAQ3B,MAAM0B,GACR,IAAIhC,MAAM,mDAI5B,kBAAkB0B,GACd,OAAOA,EAGX,iBAAiBnB,EAASnD,GAItB,OAAOA,EAAMoC,MAqGrB1C,EAAUE,SAASkF,IAAI,0BAA2BhF,GAClDJ,EAAUE,SAASkF,IAAI,yBAjGvB,cAAqCnF,EACjC,YAAYoF,GACR,IAAKA,IAAWA,EAAOC,KACnB,KAAM,qEAEVC,SAASC,WAEb,UAAUH,GACNE,MAAME,UAAUJ,GAChB1D,KAAK+D,MAAQL,EAAOC,KAGxB,WAAWjF,EAAOC,EAAOC,GAErB,GAAID,EAAMqF,WAAarF,EAAMqF,SAAShE,KAAK+D,OACvC,KAAM,GAAG/D,KAAKiE,YAAYC,gEAAgElE,KAAK+D,QAGnG,OAAOI,QAAQC,QAAQjE,KAAKyB,MAAMzB,KAAKC,UAAUzB,EAAMqF,SAAShE,KAAK+D,OAAiB,YAG1F,kBAAkBd,GAGd,MAAMoB,EAAe,IAAIC,OAAO,iDAChC,OAAOrB,EAAKnD,IAAKyE,IACb,MAAMC,EAAQD,EAAYE,QAAQD,MAAMH,GACxC,MAAO,CACHI,QAASF,EAAYE,QACrBC,WAAYF,EAAM,GAClBG,UAAWH,EAAM,GACjBI,WAAYJ,EAAM,GAClBK,gBAAiB,EAAIN,EAAYO,QACjCC,YAAaC,KAAKC,MAAMV,EAAYW,WAEzCC,KAAK,CAACC,EAAGC,KACRD,EAAIA,EAAEX,UACNY,EAAIA,EAAEZ,UAEM,EACDW,EAAIC,EACJ,EAGA,MAsDvBhH,EAAUE,SAASkF,IAAI,6BAxCvB,cAAyCjF,EACrC,sBACI,MAAO,CAAC,UAAW,kBAGvB,iBAAiByE,EAAMtE,GAInB,MAAM2G,EAAwBtF,KAAKuF,qBAAqC,eAClEC,EAAiBxF,KAAKuF,qBAA8B,QAGpDE,EAAkB9G,EAAMqF,SAASsB,GACjCI,EAAY/G,EAAMqF,SAASwB,GAE3BG,EAAqB,GAiB3B,OAfAF,EAAgB1D,OAAOmB,SAAQ,SAAU0C,GAChC9I,OAAOkB,UAAUC,eAAe1B,KAAKoJ,EAAoBC,EAAOzC,SACjEwC,EAAmBC,EAAOzC,OAAS,IAEvCwC,EAAmBC,EAAOzC,OAAO0C,KAAKD,EAAOV,WAIjDQ,EAAUxC,SAAQ,SAAU4C,GACxB,MAAMC,EAAUD,EAAKE,UACfC,EAAQN,EAAmBI,GAC7BE,IACAH,EAAKI,wBAA0BlB,KAAKmB,IAAIC,MAAM,KAAMH,OAGrDP,KAWM,oBAAdrH,WAGPA,UAAUgI,IAAIjI,GAIH,a,+BCpQf,SAASkI,EAAoBC,EAAYC,EAAOC,GAE5C,GAAKD,GAASC,IAAaD,IAASC,EAChC,MAAM,IAAIlF,MAASgF,EAAH,gGAGpB,GAAIC,IAAU,CAAC,SAAU,UAAUE,SAASF,GACxC,MAAM,IAAIjF,MAASgF,EAAH,6CAZxB,8eAqBA,MAAMjI,EACF,YAAYoF,GAKR1D,KAAK2G,cAAe,EACpB3G,KAAK4G,WAAa,KAIlB5G,KAAK6G,iBAAmB,KACxB7G,KAAK8G,eAAiB,KAOtB9G,KAAK+G,mBAAoB,EAGzB/G,KAAK8D,UAAUJ,GAWnB,UAAUA,GAEN1D,KAAKgH,OAAStD,EAAOsD,QAAU,GAgBnC,YAAYtI,EAAOC,EAAOC,GAQtBoB,KAAKE,OAAOxB,EAAOC,EAAOC,GAE1B,MAAMqI,EAAgBvI,EAAM4B,KACtB,iBAACuG,EAAgB,eAAEC,GAAkB9G,KAC3C,OAAI6G,GAAoBnI,EAAM6B,OAASsG,GAAoBC,GAAkBpI,EAAM+B,KAAOqG,EAC/E,GAAGG,KAAiBJ,KAAoBC,IAExC,GAAGpI,EAAM4B,OAAO5B,EAAM6B,SAAS7B,EAAM+B,MAQpD,OAAO/B,EAAOC,EAAOC,GACjB,OAAOoB,KAAKC,IAYhB,aAAavB,EAAOC,EAAOC,GACvB,MAAMqB,EAAMD,KAAKE,OAAOxB,EAAOC,EAAOC,GACtC,OAAOqC,MAAMhB,GAAKmB,KAAMC,IACpB,IAAKA,EAASC,GACV,MAAM,IAAIC,MAAMF,EAASG,YAE7B,OAAOH,EAASI,SAYxB,WAAW/C,EAAOC,EAAOC,GACrB,IAAIsI,EACJ,MAAMC,EAAWnH,KAAKgB,YAAYtC,EAAOC,EAAOC,GAahD,OAXIoB,KAAK2G,mBAAqC,IAAf,GAA8BQ,IAAanH,KAAK4G,WAC3EM,EAAM/C,QAAQC,QAAQpE,KAAKoH,kBAE3BF,EAAMlH,KAAKqH,aAAa3I,EAAOC,EAAOC,GAClCoB,KAAK2G,eACL3G,KAAK4G,WAAaO,EAClBnH,KAAK6G,iBAAmBnI,EAAM6B,MAC9BP,KAAK8G,eAAiBpI,EAAM+B,IAC5BT,KAAKoH,gBAAkBF,IAGxBA,EAcX,kBAAkBjE,GACd,GAAIqE,MAAMC,QAAQtE,GAEd,OAAOA,EAIX,MAAMX,EAAOxF,OAAOwF,KAAKW,GACnBuE,EAAIvE,EAAKX,EAAK,IAAIC,OAKxB,IAJmBD,EAAKmF,OAAM,SAAU9J,GAEpC,OADasF,EAAKtF,GACN4E,SAAWiF,KAGvB,MAAM,IAAIjG,MAASvB,KAAKiE,YAAYtH,KAApB,uEAIpB,MAAMmF,EAAU,GACVlD,EAAS9B,OAAOwF,KAAKW,GAC3B,IAAK,IAAI7G,EAAI,EAAGA,EAAIoL,EAAGpL,IAAK,CACxB,MAAMsL,EAAS,GACf,IAAK,IAAIC,EAAI,EAAGA,EAAI/I,EAAO2D,OAAQoF,IAC/BD,EAAO9I,EAAO+I,IAAM1E,EAAKrE,EAAO+I,IAAIvL,GAExC0F,EAAQ+D,KAAK6B,GAEjB,OAAO5F,EAYX,aAAaA,EAASnD,GAElB,OAAOmD,EAkBX,cAAemB,EAAMrE,EAAQgJ,EAAUC,GAInC,IAAKP,MAAMC,QAAQtE,GACf,OAAOA,EAGX,IAAKA,EAAKV,OAEN,OAAOU,EAGX,MAAM6E,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAInJ,EAAO2D,OAAQwF,IAC/BD,EAAWC,GAAK,EAGpB,MAAMjG,EAAUmB,EAAKnD,KAAI,SAAUC,GAC/B,MAAMiI,EAAgB,GACtB,IAAK,IAAIL,EAAI,EAAGA,EAAI/I,EAAO2D,OAAQoF,IAAK,CACpC,IAAI5E,EAAMhD,EAAKnB,EAAO+I,SACJ,IAAP5E,IACP+E,EAAWH,GAAK,GAEhBE,GAASA,EAAMF,KACf5E,EAAM8E,EAAMF,GAAG5E,IAEnBiF,EAAcJ,EAASD,IAAM5E,EAEjC,OAAOiF,KAOX,OALAF,EAAW5E,SAAQ,SAAS+E,EAAG7L,GAC3B,IAAK6L,EACD,MAAM,IAAI1G,MAAM,SAAS3C,EAAOxC,gCAAgCwL,EAASxL,SAG1E0F,EAeX,iBAAiBmB,EAAMtE,EAAOC,EAAQgJ,EAAUC,GAC5C,OAAO5E,EAoBX,cAAevB,EAAM/C,EAAOC,EAAQgJ,EAAUC,GAC1C,MAAMK,EAAYlI,KAAKkI,WAAalI,KAAKiE,YAAYtH,KAChDgC,EAAMqF,WACPrF,EAAMqF,SAAW,IAGrB,MAAMrC,EAAsB,iBAARD,EAAmBvB,KAAKyB,MAAMF,GAAQA,EAG1D,OAAOyC,QAAQC,QAAQpE,KAAKmI,kBAAkBxG,EAAKsB,MAAQtB,IACtDP,KAAMgH,GAEIjE,QAAQC,QAAQpE,KAAKqI,aAAaD,EAAczJ,KACxDyC,KAAM6B,GACEkB,QAAQC,QAAQpE,KAAKsI,cAAcrF,EAAMrE,EAAQgJ,EAAUC,KACnEzG,KAAMmH,IAGL5J,EAAMqF,SAASkE,GAAaK,EACrBpE,QAAQC,QAAQpE,KAAKwI,iBAAiBD,EAAiB5J,EAAOC,EAAQgJ,EAAUC,MACxFzG,KAAMqH,IACE,CAAE1J,OAAQJ,EAAMI,QAAU,GAAIiF,SAAUrF,EAAMqF,SAAUjD,KAAM0H,KAmBjF,QAAQ/J,EAAOE,EAAQgJ,EAAUC,GAC7B,GAAI7H,KAAK0I,WAAY,CACjB,MAAMC,EAAM3I,KAAK0I,WAAWhK,EAAOE,EAAQgJ,EAAUC,GACjD7H,KAAK2I,MACLjK,EAAQiK,EAAIjK,OAASA,EACrBE,EAAS+J,EAAI/J,QAAUA,EACvBgJ,EAAWe,EAAIf,UAAYA,EAC3BC,EAAQc,EAAId,OAASA,GAI7B,OAAQlJ,GACAqB,KAAK+G,mBAAqBpI,GAASA,EAAMoC,OAASpC,EAAMoC,KAAKwB,OAGtD4B,QAAQC,QAAQzF,GAGpBqB,KAAK4I,WAAWlK,EAAOC,EAAOC,GAAQwC,KAAMM,GACxC1B,KAAK6I,cAAcnH,EAAM/C,EAAOC,EAAQgJ,EAAUC,KAUzE,MAAMiB,UAAuBxK,EACzB,UAAUoF,GAKN,GAJAE,MAAME,UAAUJ,GAGhB1D,KAAKC,IAAMyD,EAAOzD,KACbD,KAAKC,IACN,MAAM,IAAIsB,MAAM,6CAS5B,MAAMwH,UAAsBD,EACxB,WAAYpK,EAAOE,EAAQgJ,EAAUC,GAUjC,MAPA,CADiB7H,KAAKgH,OAAOgC,UAAY,KAC9B,YAAY9F,SAAQ,SAAS+F,GAC/BrK,EAAO8H,SAASuC,KACjBrK,EAAOsK,QAAQD,GACfrB,EAASsB,QAAQD,GACjBpB,EAAMqB,QAAQ,UAGf,CAACtK,OAAQA,EAAQgJ,SAASA,EAAUC,MAAMA,GAGrD,OAAQnJ,EAAOC,EAAOC,GAClB,MAAMuK,EAAWxK,EAAMI,OAAOoK,UAAYnJ,KAAKgH,OAAOP,QAAUzG,KAAKgH,OAAOmC,SAC5E,QAAuB,IAAZA,EACP,MAAM,IAAI5H,MAAM,0DAEpB,MAAO,GAAGvB,KAAKC,kCAAkCkJ,yBAAgCzK,EAAM4B,wBAAwB5B,EAAM6B,yBAAyB7B,EAAM+B,MAGxJ,kBAAmBwC,GAWf,OANAA,EAAOW,MAAMuE,kBAAkBlF,GAC3BjD,KAAKgH,QAAUhH,KAAKgH,OAAO7B,MAAQlC,EAAKV,QAAUU,EAAK,GAAa,UACpEA,EAAKkC,MAAK,SAAUC,EAAGC,GACnB,OAAOD,EAAY,SAAIC,EAAY,YAGpCpC,GAYf,MAAMmG,UAAiBN,EACnB,YAAYpF,GACRE,MAAMF,GACN1D,KAAK+G,mBAAoB,EAG7B,WAAWrI,EAAOE,GACd,GAAIA,EAAO2D,OAAS,IACM,IAAlB3D,EAAO2D,SAAiB3D,EAAO8H,SAAS,aACxC,MAAM,IAAInF,MAAM,2CAA2C3C,EAAOyK,KAAK,OAKnF,gBAAgB1K,GAqBZ,IAAI2K,EAAa,CACbC,GAAIvJ,KAAKgH,OAAOgC,SAChBrE,SAAU3E,KAAKgH,OAAOwC,eACtBtE,OAAQlF,KAAKgH,OAAOyC,aACpBC,QAAQ,MAEZ,GAAI/K,GAASA,EAAMoC,MAAQpC,EAAMoC,KAAKwB,OAAS,EAAG,CAC9C,MAAMoH,EAAQ7M,OAAOwF,KAAK3D,EAAMoC,KAAK,IAC/B6I,GAvBmBC,EAuBIF,EAtBtB,WACH,MAAMG,EAAUjG,UAChB,IAAK,IAAIzH,EAAI,EAAGA,EAAI0N,EAAQvH,OAAQnG,IAAK,CACrC,MAAM2N,EAAQD,EAAQ1N,GAChBI,EAAIqN,EAAI5H,QAAO,SAAUgH,GAC3B,OAAOA,EAAEzE,MAAMuF,MAEnB,GAAIvN,EAAE+F,OACF,OAAO/F,EAAE,GAGjB,OAAO,OAgBLwN,EAAWV,EAAWC,IAAMK,EAAU,IAAItF,OAAUgF,EAAWC,GAAd,QACvDD,EAAWC,GAAKS,GAAYJ,EAAU,gBAAkBA,EAAU,UAClEN,EAAW3E,SAAW2E,EAAW3E,UAAYiF,EAAU,gBAAiB,YACxEN,EAAWpE,OAASoE,EAAWpE,QAAU0E,EAAU,cAAe,mBAClEN,EAAWI,QAAUC,EAhCN,IAAUE,EAkC7B,OAAOP,EAGX,oBAAqB1K,EAAQgJ,GAEzB,IAAIqC,EAAM,GACV,IAAK,IAAI7N,EAAI,EAAGA,EAAIwC,EAAO2D,OAAQnG,IACb,aAAdwC,EAAOxC,IACP6N,EAAIC,WAAatL,EAAOxC,GACxB6N,EAAIE,YAAcvC,GAAYA,EAASxL,KAEvC6N,EAAIG,KAAOxL,EAAOxC,GAClB6N,EAAII,MAAQzC,GAAYA,EAASxL,IAGzC,OAAO6N,EAGX,kBAAmBhH,GAEf,OAAOA,EAUX,UAAUvE,EAAOC,EAAOC,GACpB,IAyBI0L,EADYtK,KAAKuK,oBAAoB3L,GAClBwL,KAIvB,GAHe,UAAXE,IACAA,EAAS5L,EAAM8L,UAAY7L,EAAMI,OAAOyL,UAAY,QAEzC,SAAXF,EAAmB,CACnB,IAAK3L,EAAMoC,KACP,MAAM,IAAIQ,MAAM,iDAEpB,IAAIe,EAAOtC,KAAKyK,gBAAgB9L,GAChC,IAAK2D,EAAK4C,SAAW5C,EAAKiH,GAAI,CAC1B,IAAImB,EAAU,GAOd,MANKpI,EAAKiH,KACNmB,IAAcA,EAAQnI,OAAS,KAAO,IAA3B,MAEVD,EAAK4C,SACNwF,IAAcA,EAAQnI,OAAS,KAAO,IAA3B,UAET,IAAIhB,MAAM,iDAAiDmJ,iBAAuBpI,EAAKoH,YAEjGY,EAAS3L,EAAMoC,KA5CI,SAASe,EAAS6I,GAIrC,IAAIC,EAEAA,EAHW,MAAMC,KADrBF,EAAaA,GAAc,cAIjB,SAASvF,EAAGC,GACd,OAAOD,EAAIC,GAGT,SAASD,EAAGC,GACd,OAAOD,EAAIC,GAGnB,IAAIyF,EAAahJ,EAAQ,GAAG6I,GAAaI,EAAa,EACtD,IAAK,IAAI3O,EAAI,EAAGA,EAAI0F,EAAQS,OAAQnG,IAC5BwO,EAAI9I,EAAQ1F,GAAGuO,GAAaG,KAC5BA,EAAahJ,EAAQ1F,GAAGuO,GACxBI,EAAa3O,GAGrB,OAAO2O,EAuBaC,CAAiBrM,EAAMoC,KAAMuB,EAAK4C,SAAS5C,EAAKiH,IAIxE,MACM/E,EAAQ8F,GAAUA,EAAO9F,MADV,0EAGrB,IAAKA,EACD,MAAM,IAAIjD,MAAM,kEAEpB,MAAO0J,EAAU5K,EAAO6K,EAAKC,EAAKC,GAAO5G,EAGzC,IAAI6G,EAAmB,GAAGhL,KAAS6K,IAKnC,OAJIC,GAAOC,IACPC,GAAoB,IAAIF,KAAOC,KAG5B,CAACC,EAAkBJ,GAG9B,OAAOvM,EAAOC,EAAOC,GAOjB,MAAM4H,EAAQ9H,EAAM4M,cAAgBtL,KAAKgH,OAAOR,OAAS,SACzD,IAAIC,EAAS/H,EAAM6M,WAAavL,KAAKgH,OAAOP,QAAU,QACtD,MAAM+E,EAAa9M,EAAM+M,QAAUzL,KAAKgH,OAAOwE,YAAc,MACvDtK,EAASlB,KAAKgH,OAAO9F,QAAU,UAEtB,UAAXuF,GAAgC,WAAVD,IAEtBC,EAAS,eAGbH,EAAoBtG,KAAKiE,YAAYtH,KAAM6J,EAAO,MAElD,MAAO6E,EAAkBK,GAAc1L,KAAK2L,UAAUjN,EAAOC,EAAOC,GAKpE,OAFAD,EAAMI,OAAOyL,SAAWkB,EAEhB,CACJ1L,KAAKC,IAAK,iBAAkBuG,EAAO,eAAgBC,EAAQ,gBAAiB+E,EAAY,YACxF,gBAAiBtK,EACjB,YAAa0K,mBAAmBP,GAChC,UAAWO,mBAAmBlN,EAAM4B,KACpC,UAAWsL,mBAAmBlN,EAAM6B,OACpC,SAAUqL,mBAAmBlN,EAAM+B,MACrC4I,KAAK,IAGX,YAAY3K,EAAOC,EAAOC,GACtB,MAAMiN,EAAOjI,MAAM5C,YAAYtC,EAAOC,EAAOC,GAC7C,IAAI6H,EAAS/H,EAAM6M,WAAavL,KAAKgH,OAAOP,QAAU,QACtD,MAAM+E,EAAa9M,EAAM+M,QAAUzL,KAAKgH,OAAOwE,YAAc,OACtDlB,EAAQwB,GAAK9L,KAAK2L,UAAUjN,EAAOC,EAAOC,GACjD,MAAO,GAAGiN,KAAQvB,KAAU7D,KAAU+E,IAG1C,iBAAiBvI,EAAMtE,EAAOC,EAAQgJ,EAAUC,GAC5C,IAAIvF,EAAOtC,KAAKyK,gBAAgB9L,GAC5BoN,EAAY/L,KAAKuK,oBAAoB3L,EAAQgJ,GACjD,IAAKtF,EAAKqC,SACN,MAAM,IAAIpD,MAAM,4CAA4Ce,EAAKoH,SA4BrE,IAAIsC,EAAY/I,EAAKgJ,QAAU,UAAY,cAK3C,OA/BiB,SAAUC,EAAMC,EAAOC,EAAQC,GAC5C,IAAIjQ,EAAI,EAAGuL,EAAI,EACf,KAAOvL,EAAI8P,EAAK3J,QAAUoF,EAAIwE,EAAMG,UAAU/J,QACtC2J,EAAK9P,GAAGkG,EAAKqC,YAAcwH,EAAMG,UAAU3E,IAC3CuE,EAAK9P,GAAGgQ,GAAUD,EAAME,GAAQ1E,GAChCvL,IACAuL,KACOuE,EAAK9P,GAAGkG,EAAKqC,UAAYwH,EAAMG,UAAU3E,GAChDvL,IAEAuL,IAiBZ4E,CAAS5N,EAAMoC,KAAMkC,EAAM8I,EAAU1B,MAAO2B,GACxCD,EAAU7B,YAAcvL,EAAMI,OAAOyL,UAdnB,SAAUvH,EAAMuJ,EAAQC,EAASC,EAAYC,GAC/D,IAAK,IAAIvQ,EAAI,EAAGA,EAAI6G,EAAKV,OAAQnG,IACzB6G,EAAK7G,GAAGqQ,IAAYxJ,EAAK7G,GAAGqQ,KAAaD,GACzCvJ,EAAK7G,GAAGsQ,GAAc,EACtBzJ,EAAK7G,GAAGuQ,GAAa,GAErB1J,EAAK7G,GAAGsQ,GAAc,EAS9BE,CAAcjO,EAAMoC,KAAMpC,EAAMI,OAAOyL,SAAUlI,EAAKiH,GAAIwC,EAAU5B,YAAa4B,EAAU1B,OAExF1L,EAAMoC,KAGjB,aAAarC,EAAOC,EAAOC,GAEvB,IAAIqB,EAAMD,KAAKE,OAAOxB,EAAOC,EAAOC,GAChCiO,EAAW,CAAE5J,KAAM,IACnB6J,EAAgB,SAAU7M,GAC1B,OAAOgB,MAAMhB,GAAKmB,OAAOA,KAAMC,IAC3B,IAAKA,EAASC,GACV,MAAM,IAAIC,MAAMF,EAASG,YAE7B,OAAOH,EAASI,SACjBL,MAAK,SAAS2L,GAKb,OAJAA,EAAU5M,KAAKyB,MAAMmL,GACrBjQ,OAAOwF,KAAKyK,EAAQ9J,MAAMC,SAAQ,SAAUvF,GACxCkP,EAAS5J,KAAKtF,IAAQkP,EAAS5J,KAAKtF,IAAQ,IAAIqP,OAAOD,EAAQ9J,KAAKtF,OAEpEoP,EAAQE,KACDH,EAAcC,EAAQE,MAE1BJ,MAGf,OAAOC,EAAc7M,IAa7B,MAAMiN,UAAsBpE,EACxB,YAAYpF,GACRE,MAAMF,GACN1D,KAAK+G,mBAAoB,EAG7B,OAAOrI,EAAOC,EAAOC,GAGjB,MAAMuO,EAAezO,EAAM4M,cAAgBtL,KAAKgH,OAAOR,MACvDF,EAAoBtG,KAAKiE,YAAYtH,KAAMwQ,EAAc,MAOzD,MAAMC,EAAmC,WAAjBD,EAA6B,EAAI,EACnD1G,EAASzG,KAAKgH,OAAOP,QAAU2G,EACrC,MAAO,GAAGpN,KAAKC,4CAA8CwG,mBAAwB/H,EAAM4B,mBAAmB5B,EAAM6B,oBAAoB7B,EAAM+B,MAGlJ,gBAAgBqB,GAEZ,MAEMuL,EAFcvQ,OAAOwF,KAAKR,GAEHwL,MAAK,SAAUvN,GACxC,OAAOA,EAAKyE,MAAM,0BAGtB,IAAK6I,EACD,MAAM,IAAI9L,MAAM,0DAEpB,MAAO,CAAE,IAAO8L,GAGpB,cAAepK,EAAMrE,EAAQgJ,EAAUC,GAEnC,OAAO5E,EAGX,iBAAiBA,EAAMtE,EAAOC,EAAQgJ,EAAUC,GAC5C,IAAK5E,EAAKV,OACN,OAAO5D,EAAMoC,KAKjB,MACMwM,EAAc3F,EAAShJ,EAAO4O,QADpB,eAGhB,SAASjB,EAASL,EAAMC,EAAOvN,EAAQgJ,EAAUC,GAE7C,MAAM4F,EAAYvB,EAAwB,mBAAK,EAE/C,GADAA,EAAwB,kBAAIuB,EAAY,IACzBvB,EAAKqB,IAAgBrB,EAAKqB,GAAepB,EAAa,YAMrE,IAAK,IAAIxE,EAAI,EAAGA,EAAI/I,EAAO2D,OAAQoF,IAAK,CACpC,MAAM+F,EAAK9O,EAAO+I,GACZgG,EAAO/F,EAASD,GAEtB,IAAI5E,EAAMoJ,EAAMuB,GACZ7F,GAASA,EAAMF,KACf5E,EAAM8E,EAAMF,GAAG5E,IAEnBmJ,EAAKyB,GAAQ5K,GAIrB,MAAM6K,EAAa5N,KAAKyK,gBAAgB9L,EAAMoC,KAAK,IAC7C8M,EAAW7N,KAAKyK,gBAAgBxH,EAAK,IAG3C,IADA,IAAI7G,EAAI,EAAGuL,EAAI,EACRvL,EAAIuC,EAAMoC,KAAKwB,QAAUoF,EAAI1E,EAAKV,QAAQ,CAC7C,IAAI2J,EAAOvN,EAAMoC,KAAK3E,GAClB+P,EAAQlJ,EAAK0E,GAEbuE,EAAK0B,EAAW1C,OAASiB,EAAM0B,EAAS3C,MAExCqB,EAASL,EAAMC,EAAOvN,EAAQgJ,EAAUC,GACxCF,GAAK,GACEuE,EAAK0B,EAAW1C,KAAOiB,EAAM0B,EAAS3C,KAC7C9O,GAAK,EAELuL,GAAK,EAGb,OAAOhJ,EAAMoC,MAQrB,MAAM+M,UAAehF,EACjB,OAAOpK,EAAOC,EAAOC,GACjB,MAAM4H,EAAQ9H,EAAM4M,cAAgBtL,KAAKgH,OAAOR,MAChD,IAAIC,EAASzG,KAAKgH,OAAOP,OASzB,OARAH,EAAoBtG,KAAKiE,YAAYtH,KAAM6J,EAAOC,GAE9CD,IAIAC,EAAoB,WAAVD,EAAsB,EAAI,GAEjC,GAAGxG,KAAKC,wBAAwBwG,mBAAwB/H,EAAM4B,qBAAqB5B,EAAM+B,kBAAkB/B,EAAM6B,QAG5H,kBAAkB0C,GAGd,OAAOA,EAGX,cAAcA,EAAMrE,EAAQgJ,EAAUC,GAClC,OAAO5E,GAYf,MAAM8K,UAAyBjF,EAC3B,YAAYpF,GACRE,MAAMF,GACN1D,KAAK+G,mBAAoB,EAE7B,SAEI,OAAO/G,KAAKC,IAGhB,kBAAkBgD,GACd,OAAOA,EAGX,aAAavE,EAAOC,EAAOC,GACvB,MAAM4H,EAAQ9H,EAAM4M,cAAgBtL,KAAKgH,OAAOR,MAChD,IAAKA,EACD,MAAM,IAAIjF,MAAM,eAAevB,KAAKiE,YAAYtH,6CAGpD,MAAMqR,EAAoBrP,EAAMoC,KAAK8B,QAGjC,SAAUC,EAAKgD,GAEX,OADAhD,EAAIgD,EAAKE,WAAa,KACflD,IAEX,IAEJ,IAAImL,EAAQnR,OAAOwF,KAAK0L,GAAmBlO,KAAI,SAAUkG,GAIrD,MAAO,GAFO,IAAIA,EAAUkI,QAAQ,iBAAkB,4BAEflI,yBAAiCQ,sMAG5E,IAAKyH,EAAM1L,OAEP,OAAO4B,QAAQC,QAAQ,CAAEnB,KAAM,OAGnCgL,EAAQ,IAAIA,EAAM5E,KAAK,SACvB,MAAMpJ,EAAMD,KAAKE,OAAOxB,EAAOC,EAAOC,GAEhCmC,EAAOZ,KAAKC,UAAU,CAAE6N,MAAOA,IAKrC,OAAOhN,MAAMhB,EAAK,CAAEiB,OAAQ,OAAQH,OAAMI,QAJ1B,CAAE,eAAgB,sBAImBC,KAAMC,GAClDA,EAASC,GAGPD,EAASI,OAFL,IAGZ6B,MAAO6K,GAAQ,IAGtB,iBAAiBlL,EAAMtE,EAAOC,EAAQgJ,EAAUC,GAC5C,OAAK5E,GAILtE,EAAMoC,KAAKmC,SAAQ,SAAS4C,GAExB,MAAMsI,EAAQ,IAAItI,EAAKE,UAAUkI,QAAQ,iBAAkB,KACrDG,EAAapL,EAAKmL,IAAUnL,EAAKmL,GAA0B,kBAC7DC,GAEAvR,OAAOwF,KAAK+L,GAAYnL,SAAQ,SAAUvF,GACtC,IAAIoF,EAAMsL,EAAW1Q,QACI,IAAdmI,EAAKnI,KACM,iBAAPoF,GAAmBA,EAAIuL,WAAW5H,SAAS,OAClD3D,EAAMwL,WAAWxL,EAAIyL,QAAQ,KAEjC1I,EAAKnI,GAAOoF,SAKrBpE,EAAMoC,MApBFpC,GA4BnB,MAAM8P,UAAiB3F,EACnB,OAAOpK,EAAOC,EAAOC,GACjB,MAAM4H,EAAQ9H,EAAM4M,cAAgBtL,KAAKgH,OAAOR,MAChD,IAAIC,EAASzG,KAAKgH,OAAOP,OAMzB,OALAH,EAAoBtG,KAAKiE,YAAYC,YAAasC,EAAOC,GAErDD,IACAC,EAAoB,WAAVD,EAAsB,GAAK,IAElC,GAAGxG,KAAKC,oBAAoBwG,wBAA6B/H,EAAM4B,wBAAwB5B,EAAM+B,uBAAuB/B,EAAM6B,SAezI,MAAMmO,UAAqBpQ,EACvB,UAAU2E,GAENjD,KAAK2O,MAAQ1L,EAEjB,WAAWvE,EAAOC,EAAOC,GACrB,OAAOuF,QAAQC,QAAQpE,KAAK2O,QAWpC,MAAMC,UAAiB9F,EACnB,OAAOpK,EAAOC,EAAOC,GACjB,MAAM4H,GAAS9H,EAAM4M,aAAe,CAAC5M,EAAM4M,cAAgB,OAAStL,KAAKgH,OAAOR,MAChF,IAAKA,IAAUc,MAAMC,QAAQf,KAAWA,EAAMjE,OAC1C,MAAM,IAAIhB,MAAM,CAAC,cAAevB,KAAKiE,YAAYC,YAAa,6EAA6EmF,KAAK,MASpJ,MAPY,CACRrJ,KAAKC,IACL,uBAAwB2L,mBAAmBlN,EAAM+F,SAAU,oBAC3D+B,EAAM1G,KAAI,SAAUC,GAChB,MAAO,SAAS6L,mBAAmB7L,MACpCsJ,KAAK,MAEDA,KAAK,IAGpB,YAAY3K,EAAOC,EAAOC,GAEtB,OAAOoB,KAAKE,OAAOxB,EAAOC,EAAOC,IAqBzC,MAAMJ,UAAwBF,EAC1B,YAAYoF,GAGR,GAFAE,MAAMF,IAEDA,IAAWA,EAAOmL,QACnB,MAAM,IAAItN,MAAM,2GAWpBvB,KAAKuF,qBAAuB7B,EAAOmL,QAGnC,MAAMC,EAAgBhS,OAAOwF,KAAKoB,EAAOmL,SAGzC7O,KAAK+O,sBAAsB7L,QAAS6E,IAChC,IAAK+G,EAAcpI,SAASqB,GAExB,MAAM,IAAIxG,MAAM,qBAAqBvB,KAAKiE,YAAYtH,kDAAkDoL,OAMpH,aAEA,WAAWrJ,EAAOC,EAAOC,GASrB,OANA9B,OAAOwF,KAAKtC,KAAKuF,sBAAsBrC,QAASzF,IAC5C,MAAMuR,EAAkBhP,KAAKuF,qBAAqB9H,GAClD,GAAIkB,EAAMqF,WAAarF,EAAMqF,SAASgL,GAClC,MAAM,IAAIzN,MAAM,GAAGvB,KAAKiE,YAAYtH,yDAAyDqS,OAG9F7K,QAAQC,QAAQzF,EAAMoC,MAAQ,IAGzC,cAAckC,EAAMtE,EAAOC,EAAQgJ,EAAUC,GAMzC,OAAO1D,QAAQC,QAAQpE,KAAKwI,iBAAiBvF,EAAMtE,EAAOC,EAAQgJ,EAAUC,IACvEzG,MAAK,SAASqH,GACX,MAAO,CAAC1J,OAAQJ,EAAMI,QAAU,GAAIiF,SAAUrF,EAAMqF,UAAY,GAAIjD,KAAM0H,MAItF,iBAAiB3G,EAASnD,GAEtB,MAAM,IAAI4C,MAAM,iDAOpB,sBACI,MAAM,IAAIA,MAAM,oF,gBC1hCxBpF,EAAOD,QAAU+S,a","file":"ext/lz-aggregation-tests.min.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 12);\n","/** @module */\n/*\n * LocusZoom extensions used to calculate and render aggregation test results. Because these calculations depend on an\n *   external library, the special data sources are defined here, rather than in LocusZoom core code.\n *\n *     The page must incorporate and load all libraries before this file can be used, including:\n *    - Vendor assets\n *    - LocusZoom\n *    - raremetal.js (available via NPM or a related CDN)\n */\n// This is defined as a UMD module, to work with multiple different module systems / bundlers\n// Arcane build note: everything defined here gets registered globally. This is not a \"pure\" module, and some build\n//  systems may require being told that this file has side effects.\n\nimport {helpers} from 'raremetal.js';\nimport {BaseApiAdapter} from '../data/adapters';\n\n\nfunction install (LocusZoom) {\n    /**\n     * Data Source that calculates gene or region-based tests based on provided data\n     *   It will rarely be used by itself, but rather using a connector that attaches the results to data from\n     *   another source (like genes). Using a separate connector allows us to add caching and run this front-end\n     *   calculation only once, while using it in many different places\n     * @public\n     */\n    const BaseAdapter = LocusZoom.Adapters.get('BaseAdapter');\n    const ConnectorSource = LocusZoom.Adapters.get('ConnectorSource');\n\n    class AggregationTestSource extends BaseApiAdapter {\n        getURL(state, chain, fields) {\n            // Unlike most sources, calculations may require access to plot state data even after the initial request\n            // This example source REQUIRES that the external UI widget would store the needed test definitions in a plot state\n            //  field called `aggregation_tests` (an object {masks: [], calcs: {})\n            const required_info = state.aggregation_tests || {};\n\n            if (!chain.header) {\n                chain.header = {};\n            }\n            // All of these fields are required in order to use this datasource. TODO: Add validation?\n            chain.header.aggregation_genoset_id = required_info.genoset_id || null; // Number\n            chain.header.aggregation_genoset_build = required_info.genoset_build || null; // String\n            chain.header.aggregation_phenoset_id = required_info.phenoset_id || null;  // Number\n            chain.header.aggregation_pheno = required_info.pheno || null; // String\n            chain.header.aggregation_calcs = required_info.calcs || {};  // String[]\n            const mask_data = required_info.masks || [];\n            chain.header.aggregation_masks = mask_data;  // {name:desc}[]\n            chain.header.aggregation_mask_ids = mask_data.map(function (item) {\n                return item.name;\n            }); // Number[]\n            return this.url;\n        }\n\n        getCacheKey(state, chain, fields) {\n            this.getURL(state, chain, fields);  // TODO: This just sets the chain.header fields\n            return JSON.stringify({\n                chrom: state.chr,\n                start: state.start,\n                stop: state.end,\n                genotypeDataset: chain.header.aggregation_genoset_id,\n                phenotypeDataset: chain.header.aggregation_phenoset_id,\n                phenotype: chain.header.aggregation_pheno,\n                samples: 'ALL',\n                genomeBuild: chain.header.aggregation_genoset_build,\n                masks: chain.header.aggregation_mask_ids,\n            });\n        }\n\n        fetchRequest(state, chain, fields) {\n            const url = this.getURL(state, chain, fields);\n            const body = this.getCacheKey(state, chain, fields);\n            const headers = {\n                'Content-Type': 'application/json',\n            };\n\n            return fetch(url, {method: 'POST', body: body, headers: headers}).then((response) => {\n                if (!response.ok) {\n                    throw new Error(response.statusText);\n                }\n                return response.text();\n            }).then(function (resp) {\n                const json = typeof resp == 'string' ? JSON.parse(resp) : resp;\n                if (json.error) {\n                    // RAREMETAL-server quirk: The API sometimes returns a 200 status code for failed requests,\n                    //    with a human-readable error description as a key\n                    // For now, this should be treated strictly as an error\n                    throw new Error(json.error);\n                }\n                return json;\n            });\n        }\n\n        annotateData(records, chain) {\n            // Operate on the calculated results. The result of this method will be added to chain.discrete\n\n            // In a page using live API data, the UI would only request the masks it needs from the API.\n            // But in our demos, sometimes boilerplate JSON has more masks than the UI asked for. Limit what calcs we run (by\n            //  type, and to the set of groups requested by the user)\n\n            // The Raremetal-server API has a quirk: it returns a different payload structure if no groups are defined\n            //  for the request region. Detect when that happens and end the calculation immediately in that case\n            if (!records.groups) {\n                return { groups: [], variants: [] };\n            }\n\n            records.groups = records.groups.filter(function (item) {\n                return item.groupType === 'GENE';\n            });\n\n            const parsed = helpers.parsePortalJSON(records);\n            let groups = parsed[0];\n            const variants = parsed[1];\n            // Some APIs may return more data than we want (eg simple sites that are just serving up premade scorecov json files).\n            //  Filter the response to just what the user has chosen to analyze.\n            groups = groups.byMask(chain.header.aggregation_mask_ids);\n\n            // Determine what calculations to run\n            const calcs = chain.header.aggregation_calcs;\n            if (!calcs || Object.keys(calcs).length === 0) {\n                // If no calcs have been requested, then return a dummy placeholder immediately\n                return { variants: [], groups: [], results: [] };\n            }\n            const runner = new helpers.PortalTestRunner(groups, variants, calcs);\n\n            return runner.toJSON()\n                .then(function (res) {\n                    // Internally, raremetal helpers track how the calculation is done, but not any display-friendly values\n                    // We will annotate each mask name (id) with a human-friendly description for later use\n                    const mask_id_to_desc = chain.header.aggregation_masks.reduce(function (acc, val) {\n                        acc[val.name] = val.description;\n                        return acc;\n                    }, {});\n                    res.data.groups.forEach(function (group) {\n                        group.mask_name = mask_id_to_desc[group.mask];\n                    });\n                    return res.data;\n                })\n                .catch(function (e) {\n                    console.error(e);\n                    throw new Error('Failed to calculate aggregation test results');\n                });\n        }\n\n        normalizeResponse(data) {\n            return data;\n        }\n\n        combineChainBody(records, chain) {\n            // aggregation tests are a bit unique, in that the data is rarely used directly- instead it is used to annotate many\n            //  other layers in different ways. The calculated result has been added to `chain.discrete`, but will not be returned\n            //  as part of the response body built up by the chain\n            return chain.body;\n        }\n\n    }\n\n    class AssocFromAggregationLZ extends BaseAdapter {\n        constructor(config) {\n            if (!config || !config.from) {\n                throw 'Must specify the name of the source that contains association data';\n            }\n            super(...arguments);\n        }\n        parseInit(config) {\n            super.parseInit(config);\n            this._from = config.from;\n        }\n\n        getRequest(state, chain, fields) {\n            // Does not actually make a request. Just pick off the specific bundle of data from a known payload structure.\n            if (chain.discrete && !chain.discrete[this._from]) {\n                throw `${this.constructor.SOURCE_NAME} cannot be used before loading required data for: ${this._from}`;\n            }\n            // Copy the data so that mutations (like sorting) don't affect the original\n            return Promise.resolve(JSON.parse(JSON.stringify(chain.discrete[this._from]['variants'])));\n        }\n\n        normalizeResponse(data) {\n            // The payload structure of the association source is slightly different than the one required by association\n            //   plots. For example, we need to parse variant names and convert to log_pvalue\n            const REGEX_EPACTS = new RegExp('(?:chr)?(.+):(\\\\d+)_?(\\\\w+)?/?([^_]+)?_?(.*)?');  // match API variant strings\n            return data.map((one_variant) => {\n                const match = one_variant.variant.match(REGEX_EPACTS);\n                return {\n                    variant: one_variant.variant,\n                    chromosome: match[1],\n                    position: +match[2],\n                    ref_allele: match[3],\n                    ref_allele_freq: 1 - one_variant.altFreq,\n                    log_pvalue: -Math.log10(one_variant.pvalue),\n                };\n            }).sort((a, b) => {\n                a = a.variant;\n                b = b.variant;\n                if (a < b) {\n                    return -1;\n                } else if (a > b) {\n                    return 1;\n                } else {\n                    // names must be equal\n                    return 0;\n                }\n            });\n        }\n    }\n\n    /**\n     * A sample connector that aligns calculated aggregation test data with corresponding gene information. Returns a body\n     *   suitable for use with the genes datalayer.\n     *\n     *  To use this source, one must specify a fields array that calls first the genes source, then a dummy field from\n     *      this source. The output will be to transparently add several new fields to the genes data.\n     * @public\n     */\n    class GeneAggregationConnectorLZ extends ConnectorSource {\n        _getRequiredSources() {\n            return ['gene_ns', 'aggregation_ns'];\n        }\n\n        combineChainBody(data, chain) {\n            // The genes layer receives all results, and displays only the best pvalue for each gene\n\n            // Tie the calculated group-test results to genes with a matching name\n            const aggregation_source_id = this._source_name_mapping['aggregation_ns'];\n            const gene_source_id = this._source_name_mapping['gene_ns'];\n            // This connector assumes that genes are the main body of records from the chain, and that aggregation tests are\n            //   a standalone source that has not acted on genes data yet\n            const aggregationData = chain.discrete[aggregation_source_id];\n            const genesData = chain.discrete[gene_source_id];\n\n            const groupedAggregation = {};  // Group together all tests done on that gene- any mask, any test\n\n            aggregationData.groups.forEach(function (result) {\n                if (!Object.prototype.hasOwnProperty.call(groupedAggregation, result.group)) {\n                    groupedAggregation[result.group] = [];\n                }\n                groupedAggregation[result.group].push(result.pvalue);\n            });\n\n            // Annotate any genes that have test results\n            genesData.forEach(function (gene) {\n                const gene_id = gene.gene_name;\n                const tests = groupedAggregation[gene_id];\n                if (tests) {\n                    gene.aggregation_best_pvalue = Math.min.apply(null, tests);\n                }\n            });\n            return genesData;\n        }\n    }\n\n\n    LocusZoom.Adapters.add('AggregationTestSourceLZ', AggregationTestSource);\n    LocusZoom.Adapters.add('AssocFromAggregationLZ', AssocFromAggregationLZ);\n    LocusZoom.Adapters.add('GeneAggregationConnectorLZ', GeneAggregationConnectorLZ);\n}\n\n\nif (typeof LocusZoom !== 'undefined') {\n    // Auto-register the plugin when included as a script tag. ES6 module users must register via LocusZoom.use()\n    // eslint-disable-next-line no-undef\n    LocusZoom.use(install);\n}\n\n\nexport default install;\n","/**\n * Define standard data adapters used to retrieve data (usually from REST APIs)\n * @module\n */\n\nfunction validateBuildSource(class_name, build, source) {\n    // Build OR Source, not both\n    if ((build && source) || !(build || source)) {\n        throw new Error(`${class_name} must provide a parameter specifying either \"build\" or \"source\". It should not specify both.`);\n    }\n    // If the build isn't recognized, our APIs can't transparently select a source to match\n    if (build && !['GRCh37', 'GRCh38'].includes(build)) {\n        throw new Error(`${class_name} must specify a valid genome build number`);\n    }\n}\n\n\n/**\n * Base class for LocusZoom data sources (any). See also: BaseApiAdapter\n * @public\n */\nclass BaseAdapter {\n    constructor(config) {\n        /**\n         * Whether this source should enable caching\n         * @member {Boolean}\n         */\n        this._enableCache = true;\n        this._cachedKey = null;\n\n        // Almost all LZ sources are \"region based\". Cache the region requested and use it to determine whether\n        //   the cache would satisfy the request.\n        this._cache_pos_start = null;\n        this._cache_pos_end = null;\n\n        /**\n         * Whether this data source type is dependent on previous requests- for example, the LD source cannot annotate\n         *  association data if no data was found for that region.\n         * @member {boolean}\n         */\n        this.__dependentSource = false;\n\n        // Parse configuration options\n        this.parseInit(config);\n    }\n\n    /**\n     * Parse configuration used to create the data source. Many custom sources will override this method to suit their\n     *  needs (eg specific config options, or for sources that do not retrieve data from a URL)\n     * @protected\n     * @param {String|Object} config Basic configuration- either a url, or a config object\n     * @param {String} [config.url] The datasource URL\n     * @param {String} [config.params] Initial config params for the datasource\n     */\n    parseInit(config) {\n        /** @member {Object} */\n        this.params = config.params || {};\n    }\n\n    /**\n     * A unique identifier that indicates whether cached data is valid for this request. For most sources using GET\n     *  requests to a REST API, this is usually the region requested. Some sources will append additional params to define the request.\n     *\n     *  This means that to change caching behavior, both the URL and the cache key may need to be updated. However,\n     *      it allows most datasources to skip an extra network request when zooming in.\n     * @protected\n     * @param {Object} state Information available in plot.state (chr, start, end). Sometimes used to inject globally\n     *  available information that influences the request being made.\n     * @param {Object} chain The data chain from previous requests made in a sequence.\n     * @param fields\n     * @returns {String}\n     */\n    getCacheKey(state, chain, fields) {\n        // Most region sources, by default, will cache the largest region that satisfies the request: zooming in\n        //  should be satisfied via the cache, but pan or region change operations will cause a network request\n\n        // Some data source rely on values set in chain.header during the getURL call. (eg, the LD source uses\n        //  this to find the LD refvar) Calling this method is a backwards-compatible way of ensuring that value is set,\n        //  even on a cache hit in which getURL otherwise wouldn't be called.\n        // Some of the data sources that rely on this behavior are user-defined, hence compatibility hack\n        this.getURL(state, chain, fields);\n\n        const cache_pos_chr = state.chr;\n        const {_cache_pos_start, _cache_pos_end} = this;\n        if (_cache_pos_start && state.start >= _cache_pos_start && _cache_pos_end && state.end <= _cache_pos_end ) {\n            return `${cache_pos_chr}_${_cache_pos_start}_${_cache_pos_end}`;\n        } else {\n            return `${state.chr}_${state.start}_${state.end}`;\n        }\n    }\n\n    /**\n     * Stub: build the URL for any requests made by this source.\n     * @protected\n     */\n    getURL(state, chain, fields) {\n        return this.url;\n    }\n\n    /**\n     * Perform a network request to fetch data for this source. This is usually the method that is used to override\n     *  when defining how to retrieve data.\n     * @protected\n     * @param {Object} state The state of the parent plot\n     * @param chain\n     * @param fields\n     * @returns {Promise}\n     */\n    fetchRequest(state, chain, fields) {\n        const url = this.getURL(state, chain, fields);\n        return fetch(url).then((response) => {\n            if (!response.ok) {\n                throw new Error(response.statusText);\n            }\n            return response.text();\n        });\n    }\n\n    /**\n     * Gets the data for just this source, typically via a network request (but using cache where possible)\n     *\n     * For most use cases, it is better to override `fetchRequest` instead, to avoid bypassing the cache mechanism\n     * by accident.\n     * @protected\n     * @return {Promise}\n     */\n    getRequest(state, chain, fields) {\n        let req;\n        const cacheKey = this.getCacheKey(state, chain, fields);\n\n        if (this._enableCache && typeof(cacheKey) !== 'undefined' && cacheKey === this._cachedKey) {\n            req = Promise.resolve(this._cachedResponse);  // Resolve to the value of the current promise\n        } else {\n            req = this.fetchRequest(state, chain, fields);\n            if (this._enableCache) {\n                this._cachedKey = cacheKey;\n                this._cache_pos_start = state.start;\n                this._cache_pos_end = state.end;\n                this._cachedResponse = req;\n            }\n        }\n        return req;\n    }\n\n    /**\n     * Ensure the server response is in a canonical form, an array of one object per record. [ {field: oneval} ].\n     * If the server response contains columns, reformats the response from {column1: [], column2: []} to the above.\n     *\n     * Does not apply namespacing, transformations, or field extraction.\n     *\n     * May be overridden by data sources that inherently return more complex payloads, or that exist to annotate other\n     *  sources (eg, if the payload provides extra data rather than a series of records).\n     * @protected\n     * @param {Object[]|Object} data The original parsed server response\n     */\n    normalizeResponse(data) {\n        if (Array.isArray(data)) {\n            // Already in the desired form\n            return data;\n        }\n        // Otherwise, assume the server response is an object representing columns of data.\n        // Each array should have the same length (verify), and a given array index corresponds to a single row.\n        const keys = Object.keys(data);\n        const N = data[keys[0]].length;\n        const sameLength = keys.every(function (key) {\n            const item = data[key];\n            return item.length === N;\n        });\n        if (!sameLength) {\n            throw new Error(`${this.constructor.name} expects a response in which all arrays of data are the same length`);\n        }\n\n        // Go down the rows, and create an object for each record\n        const records = [];\n        const fields = Object.keys(data);\n        for (let i = 0; i < N; i++) {\n            const record = {};\n            for (let j = 0; j < fields.length; j++) {\n                record[fields[j]] = data[fields[j]][i];\n            }\n            records.push(record);\n        }\n        return records;\n    }\n\n    /**\n     * Hook to post-process the data returned by this source with new, additional behavior.\n     *   (eg cleaning up API values or performing complex calculations on the returned data)\n     *\n     * @protected\n     * @param {Object[]} records The parsed data from the source (eg standardized api response)\n     * @param {Object} chain The data chain object. For example, chain.headers may provide useful annotation metadata\n     * @returns {Object[]|Promise} The modified set of records\n     */\n    annotateData(records, chain) {\n        // Default behavior: no transformations\n        return records;\n    }\n\n    /**\n     * Clean up the server records for use by datalayers: extract only certain fields, with the specified names.\n     *   Apply per-field transformations as appropriate.\n     *\n     * This hook can be overridden, eg to create a source that always returns all records and ignores the \"fields\" array.\n     *  This is particularly common for sources at the end of a chain- many \"dependent\" sources do not allow\n     *  cherry-picking individual fields, in which case by **convention** the fields array specifies \"last_source_name:all\"\n     *\n     * @protected\n     * @param {Object[]} data One record object per element\n     * @param {String[]} fields The names of fields to extract (as named in the source data). Eg \"afield\"\n     * @param {String[]} outnames How to represent the source fields in the output. Eg \"namespace:afield|atransform\"\n     * @param {function[]} trans An array of transformation functions (if any). One function per data element, or null.\n     * @protected\n     */\n    extractFields (data, fields, outnames, trans) {\n        //intended for an array of objects\n        //  [ {\"id\":1, \"val\":5}, {\"id\":2, \"val\":10}]\n        // Since a number of sources exist that do not obey this format, we will provide a convenient pass-through\n        if (!Array.isArray(data)) {\n            return data;\n        }\n\n        if (!data.length) {\n            // Sometimes there are regions that just don't have data- this should not trigger a missing field error message!\n            return data;\n        }\n\n        const fieldFound = [];\n        for (let k = 0; k < fields.length; k++) {\n            fieldFound[k] = 0;\n        }\n\n        const records = data.map(function (item) {\n            const output_record = {};\n            for (let j = 0; j < fields.length; j++) {\n                let val = item[fields[j]];\n                if (typeof val != 'undefined') {\n                    fieldFound[j] = 1;\n                }\n                if (trans && trans[j]) {\n                    val = trans[j](val);\n                }\n                output_record[outnames[j]] = val;\n            }\n            return output_record;\n        });\n        fieldFound.forEach(function(v, i) {\n            if (!v) {\n                throw new Error(`field ${fields[i]} not found in response for ${outnames[i]}`);\n            }\n        });\n        return records;\n    }\n\n    /**\n     * Combine records from this source with others in the chain to yield final chain body.\n     *   Handles merging this data with other sources (if applicable).\n     *\n     * @protected\n     * @param {Object[]} data The data That would be returned from this source alone\n     * @param {Object} chain The data chain built up during previous requests\n     * @param {String[]} fields\n     * @param {String[]} outnames\n     * @param {String[]} trans\n     * @return {Promise|Object[]} The new chain body\n     */\n    combineChainBody(data, chain, fields, outnames, trans) {\n        return data;\n    }\n\n    /**\n     * Coordinates the work of parsing a response and returning records. This is broken into 4 steps, which may be\n     *  overridden separately for fine-grained control. Each step can return either raw data or a promise.\n     *\n     * @protected\n     *\n     * @param {String|Object} resp The raw data associated with the response\n     * @param {Object} chain The combined parsed response data from this and all other requests made in the chain\n     * @param {String[]} fields Array of requested field names (as they would appear in the response payload)\n     * @param {String[]} outnames  Array of field names as they will be represented in the data returned by this source,\n     *  including the namespace. This must be an array with the same length as `fields`\n     * @param {Function[]} trans The collection of transformation functions to be run on selected fields.\n     *     This must be an array with the same length as `fields`\n     * @returns {Promise} A promise that resolves to an object containing\n     *   request metadata (`headers: {}`), the consolidated data for plotting (`body: []`), and the individual responses that would be\n     *   returned by each source in the chain in isolation (`discrete: {}`)\n     */\n    parseResponse (resp, chain, fields, outnames, trans) {\n        const source_id = this.source_id || this.constructor.name;\n        if (!chain.discrete) {\n            chain.discrete = {};\n        }\n\n        const json = typeof resp == 'string' ? JSON.parse(resp) : resp;\n\n        // Perform the 4 steps of parsing the payload and return a combined chain object\n        return Promise.resolve(this.normalizeResponse(json.data || json))\n            .then((standardized) => {\n                // Perform calculations on the data from just this source\n                return Promise.resolve(this.annotateData(standardized, chain));\n            }).then((data) => {\n                return Promise.resolve(this.extractFields(data, fields, outnames, trans));\n            }).then((one_source_body) => {\n                // Store a copy of the data that would be returned by parsing this source in isolation (and taking the\n                //   fields array into account). This is useful when we want to re-use the source output in many ways.\n                chain.discrete[source_id] = one_source_body;\n                return Promise.resolve(this.combineChainBody(one_source_body, chain, fields, outnames, trans));\n            }).then((new_body) => {\n                return { header: chain.header || {}, discrete: chain.discrete, body: new_body };\n            });\n    }\n\n    /**\n     * Fetch the data from the specified data source, and apply transformations requested by an external consumer.\n     * This is the public-facing datasource method that will most be called by the plot, but custom data sources will\n     *  almost never want to override this method directly- more specific hooks are provided to control individual pieces\n     *  of the request lifecycle.\n     *\n     * @private\n     * @param {Object} state The current \"state\" of the plot, such as chromosome and start/end positions\n     * @param {String[]} fields Array of field names that the plot has requested from this data source. (without the \"namespace\" prefix)\n     * @param {String[]} outnames  Array describing how the output data should refer to this field. This represents the\n     *     originally requested field name, including the namespace. This must be an array with the same length as `fields`\n     * @param {Function[]} trans The collection of transformation functions to be run on selected fields.\n     *     This must be an array with the same length as `fields`\n     * @returns {function} A callable operation that can be used as part of the data chain\n     */\n    getData(state, fields, outnames, trans) {\n        if (this.preGetData) { // TODO try to remove this method if at all possible\n            const pre = this.preGetData(state, fields, outnames, trans);\n            if (this.pre) {\n                state = pre.state || state;\n                fields = pre.fields || fields;\n                outnames = pre.outnames || outnames;\n                trans = pre.trans || trans;\n            }\n        }\n\n        return (chain) => {\n            if (this.__dependentSource && chain && chain.body && !chain.body.length) {\n                // A \"dependent\" source should not attempt to fire a request if there is no data for it to act on.\n                // Therefore, it should simply return the previous data chain.\n                return Promise.resolve(chain);\n            }\n\n            return this.getRequest(state, chain, fields).then((resp) => {\n                return this.parseResponse(resp, chain, fields, outnames, trans);\n            });\n        };\n    }\n}\n\n/**\n * Base source for LocusZoom data sources that receive their data over the web. Adds default config parameters\n *  (and potentially other behavior) that are relevant to URL-based requests.\n */\nclass BaseApiAdapter extends BaseAdapter {\n    parseInit(config) {\n        super.parseInit(config);\n\n        /** @member {String} */\n        this.url = config.url;\n        if (!this.url) {\n            throw new Error('Source not initialized with required URL');\n        }\n    }\n}\n\n/**\n * Data Source for Association Data from the LocusZoom/ Portaldev API (or compatible). Defines how to make a requesr\n * @public\n */\nclass AssociationLZ extends BaseApiAdapter {\n    preGetData (state, fields, outnames, trans) {\n        // TODO: Modify internals to see if we can go without this method\n        const id_field = this.params.id_field || 'id';\n        [id_field, 'position'].forEach(function(x) {\n            if (!fields.includes(x)) {\n                fields.unshift(x);\n                outnames.unshift(x);\n                trans.unshift(null);\n            }\n        });\n        return {fields: fields, outnames:outnames, trans:trans};\n    }\n\n    getURL (state, chain, fields) {\n        const analysis = chain.header.analysis || this.params.source || this.params.analysis;  // Old usages called this param \"analysis\"\n        if (typeof analysis == 'undefined') {\n            throw new Error('Association source must specify an analysis ID to plot');\n        }\n        return `${this.url}results/?filter=analysis in ${analysis} and chromosome in  '${state.chr}' and position ge ${state.start} and position le ${state.end}`;\n    }\n\n    normalizeResponse (data) {\n        // Some association sources do not sort their data in a predictable order, which makes it hard to reliably\n        //  align with other sources (such as LD). For performance reasons, sorting is an opt-in argument.\n        // TODO: Consider more fine grained sorting control in the future. This was added as a very specific\n        //   workaround for the original T2D portal.\n        data = super.normalizeResponse(data);\n        if (this.params && this.params.sort && data.length && data[0]['position']) {\n            data.sort(function (a, b) {\n                return a['position'] - b['position'];\n            });\n        }\n        return data;\n    }\n}\n\n/**\n * Fetch linkage disequilibrium information from a UMich LDServer-compatible API\n *\n * This source is designed to connect its results to association data, and therefore depends on association data having\n *  been loaded by a previous request in the data chain.\n *\n * In older versions of LocusZoom, this was known as \"LDServer\". A prior source (targeted at older APIs) has been removed.\n */\nclass LDServer extends BaseApiAdapter {\n    constructor(config) {\n        super(config);\n        this.__dependentSource = true;\n    }\n\n    preGetData(state, fields) {\n        if (fields.length > 1) {\n            if (fields.length !== 2 || !fields.includes('isrefvar')) {\n                throw new Error(`LD does not know how to get all fields: ${fields.join(', ')}`);\n            }\n        }\n    }\n\n    findMergeFields(chain) {\n        // Find the fields (as provided by a previous step in the chain, like an association source) that will be needed to\n        //  combine LD data with existing information\n\n        // Since LD information may be shared across multiple assoc sources with different namespaces,\n        //   we use regex to find columns to join on, rather than requiring exact matches\n        const exactMatch = function (arr) {\n            return function () {\n                const regexes = arguments;\n                for (let i = 0; i < regexes.length; i++) {\n                    const regex = regexes[i];\n                    const m = arr.filter(function (x) {\n                        return x.match(regex);\n                    });\n                    if (m.length) {\n                        return m[0];\n                    }\n                }\n                return null;\n            };\n        };\n        let dataFields = {\n            id: this.params.id_field,\n            position: this.params.position_field,\n            pvalue: this.params.pvalue_field,\n            _names_:null,\n        };\n        if (chain && chain.body && chain.body.length > 0) {\n            const names = Object.keys(chain.body[0]);\n            const nameMatch = exactMatch(names);\n            // Internally, fields are generally prefixed with the name of the source they come from.\n            // If the user provides an id_field (like `variant`), it should work across data sources( `assoc1:variant`,\n            //  assoc2:variant), but not match fragments of other field names (assoc1:variant_thing)\n            // Note: these lookups hard-code a couple of common fields that will work based on known APIs in the wild\n            const id_match = dataFields.id && nameMatch(new RegExp(`${dataFields.id}\\\\b`));\n            dataFields.id = id_match || nameMatch(/\\bvariant\\b/) || nameMatch(/\\bid\\b/);\n            dataFields.position = dataFields.position || nameMatch(/\\bposition\\b/i, /\\bpos\\b/i);\n            dataFields.pvalue = dataFields.pvalue || nameMatch(/\\bpvalue\\b/i, /\\blog_pvalue\\b/i);\n            dataFields._names_ = names;\n        }\n        return dataFields;\n    }\n\n    findRequestedFields (fields, outnames) {\n        // Assumption: all usages of this source will only ever ask for \"isrefvar\" or \"state\". This maps to output names.\n        let obj = {};\n        for (let i = 0; i < fields.length; i++) {\n            if (fields[i] === 'isrefvar') {\n                obj.isrefvarin = fields[i];\n                obj.isrefvarout = outnames && outnames[i];\n            } else {\n                obj.ldin = fields[i];\n                obj.ldout = outnames && outnames[i];\n            }\n        }\n        return obj;\n    }\n\n    normalizeResponse (data) {\n        // The LD API payload does not obey standard format conventions; do not try to transform it.\n        return data;\n    }\n\n    /**\n     * Get the LD reference variant, which by default will be the most significant hit in the assoc results\n     *   This will be used in making the original query to the LD server for pairwise LD information\n     * @returns String[] Two strings: 1) the marker id (expected to be in `chr:pos_ref/alt` format) of the reference\n     *  variant, and 2) the marker ID as it appears in the original dataset that we are joining to, so that the exact\n     *  refvar can be marked when plotting the data..\n     */\n    getRefvar(state, chain, fields) {\n        let findExtremeValue = function(records, pval_field) {\n            // Finds the most significant hit (smallest pvalue, or largest -log10p). Will try to auto-detect the appropriate comparison.\n            pval_field = pval_field || 'log_pvalue';  // The official LZ API returns log_pvalue\n            const is_log = /log/.test(pval_field);\n            let cmp;\n            if (is_log) {\n                cmp = function(a, b) {\n                    return a > b;\n                };\n            } else {\n                cmp = function(a, b) {\n                    return a < b;\n                };\n            }\n            let extremeVal = records[0][pval_field], extremeIdx = 0;\n            for (let i = 1; i < records.length; i++) {\n                if (cmp(records[i][pval_field], extremeVal)) {\n                    extremeVal = records[i][pval_field];\n                    extremeIdx = i;\n                }\n            }\n            return extremeIdx;\n        };\n\n        let reqFields = this.findRequestedFields(fields);\n        let refVar = reqFields.ldin;\n        if (refVar === 'state') {\n            refVar = state.ldrefvar || chain.header.ldrefvar || 'best';\n        }\n        if (refVar === 'best') {\n            if (!chain.body) {\n                throw new Error('No association data found to find best pvalue');\n            }\n            let keys = this.findMergeFields(chain);\n            if (!keys.pvalue || !keys.id) {\n                let columns = '';\n                if (!keys.id) {\n                    columns += `${columns.length ? ', ' : ''}id`;\n                }\n                if (!keys.pvalue) {\n                    columns += `${columns.length ? ', ' : ''}pvalue`;\n                }\n                throw new Error(`Unable to find necessary column(s) for merge: ${columns} (available: ${keys._names_})`);\n            }\n            refVar = chain.body[findExtremeValue(chain.body, keys.pvalue)][keys.id];\n        }\n        // Some datasets, notably the Portal, use a different marker format.\n        //  Coerce it into one that will work with the LDServer API. (CHROM:POS_REF/ALT)\n        const REGEX_MARKER = /^(?:chr)?([a-zA-Z0-9]+?)[_:-](\\d+)[_:|-]?(\\w+)?[/_:|-]?([^_]+)?_?(.*)?/;\n        const match = refVar && refVar.match(REGEX_MARKER);\n\n        if (!match) {\n            throw new Error('Could not request LD for a missing or incomplete marker format');\n        }\n        const [original, chrom, pos, ref, alt] = match;\n        // Currently, the LD server only accepts full variant specs; it won't return LD w/o ref+alt. Allowing\n        //  a partial match at most leaves room for potential future features.\n        let refVar_formatted = `${chrom}:${pos}`;\n        if (ref && alt) {\n            refVar_formatted += `_${ref}/${alt}`;\n        }\n\n        return [refVar_formatted, original];\n    }\n\n    getURL(state, chain, fields) {\n        // Accept the following params in this.params:\n        // - method (r, rsquare, cov)\n        // - source (aka panel)\n        // - population (ALL, AFR, EUR, etc)\n        // - build\n        // The LD source/pop can be overridden from plot.state for dynamic layouts\n        const build = state.genome_build || this.params.build || 'GRCh37'; // This isn't expected to change after the data is plotted.\n        let source = state.ld_source || this.params.source || '1000G';\n        const population = state.ld_pop || this.params.population || 'ALL';  // LDServer panels will always have an ALL\n        const method = this.params.method || 'rsquare';\n\n        if (source === '1000G' && build === 'GRCh38') {\n            // For build 38 (only), there is a newer/improved 1000G LD panel available that uses WGS data. Auto upgrade by default.\n            source = '1000G-FRZ09';\n        }\n\n        validateBuildSource(this.constructor.name, build, null);  // LD doesn't need to validate `source` option\n\n        const [refVar_formatted, refVar_raw] = this.getRefvar(state, chain, fields);\n\n        // Preserve the user-provided variant spec for use when matching to assoc data\n        chain.header.ldrefvar = refVar_raw;\n\n        return  [\n            this.url, 'genome_builds/', build, '/references/', source, '/populations/', population, '/variants',\n            '?correlation=', method,\n            '&variant=', encodeURIComponent(refVar_formatted),\n            '&chrom=', encodeURIComponent(state.chr),\n            '&start=', encodeURIComponent(state.start),\n            '&stop=', encodeURIComponent(state.end),\n        ].join('');\n    }\n\n    getCacheKey(state, chain, fields) {\n        const base = super.getCacheKey(state, chain, fields);\n        let source = state.ld_source || this.params.source || '1000G';\n        const population = state.ld_pop || this.params.population || 'ALL';  // LDServer panels will always have an ALL\n        const [refVar, _] = this.getRefvar(state, chain, fields);\n        return `${base}_${refVar}_${source}_${population}`;\n    }\n\n    combineChainBody(data, chain, fields, outnames, trans) {\n        let keys = this.findMergeFields(chain);\n        let reqFields = this.findRequestedFields(fields, outnames);\n        if (!keys.position) {\n            throw new Error(`Unable to find position field for merge: ${keys._names_}`);\n        }\n        const leftJoin = function (left, right, lfield, rfield) {\n            let i = 0, j = 0;\n            while (i < left.length && j < right.position2.length) {\n                if (left[i][keys.position] === right.position2[j]) {\n                    left[i][lfield] = right[rfield][j];\n                    i++;\n                    j++;\n                } else if (left[i][keys.position] < right.position2[j]) {\n                    i++;\n                } else {\n                    j++;\n                }\n            }\n        };\n        const tagRefVariant = function (data, refvar, idfield, outrefname, outldname) {\n            for (let i = 0; i < data.length; i++) {\n                if (data[i][idfield] && data[i][idfield] === refvar) {\n                    data[i][outrefname] = 1;\n                    data[i][outldname] = 1; // For label/filter purposes, implicitly mark the ref var as LD=1 to itself\n                } else {\n                    data[i][outrefname] = 0;\n                }\n            }\n        };\n\n        // LD servers vary slightly. Some report corr as \"rsquare\", others as \"correlation\"\n        let corrField = data.rsquare ? 'rsquare' : 'correlation';\n        leftJoin(chain.body, data, reqFields.ldout, corrField);\n        if (reqFields.isrefvarin && chain.header.ldrefvar) {\n            tagRefVariant(chain.body, chain.header.ldrefvar, keys.id, reqFields.isrefvarout, reqFields.ldout);\n        }\n        return chain.body;\n    }\n\n    fetchRequest(state, chain, fields) {\n        // The API is paginated, but we need all of the data to render a plot. Depaginate and combine where appropriate.\n        let url = this.getURL(state, chain, fields);\n        let combined = { data: {} };\n        let chainRequests = function (url) {\n            return fetch(url).then().then((response) => {\n                if (!response.ok) {\n                    throw new Error(response.statusText);\n                }\n                return response.text();\n            }).then(function(payload) {\n                payload = JSON.parse(payload);\n                Object.keys(payload.data).forEach(function (key) {\n                    combined.data[key] = (combined.data[key] || []).concat(payload.data[key]);\n                });\n                if (payload.next) {\n                    return chainRequests(payload.next);\n                }\n                return combined;\n            });\n        };\n        return chainRequests(url);\n    }\n}\n\n/**\n * Data source for GWAS catalogs of known variants\n * @public\n * @class\n * @param {Object|String} init Configuration (URL or object)\n * @param {Object} [init.params] Optional configuration parameters\n * @param {Number} [init.params.source=2] The ID of the chosen catalog. Defaults to EBI GWAS catalog, GRCh37\n * @param {('strict'|'loose')} [init.params.match_type='strict'] Whether to match on exact variant, or just position.\n */\nclass GwasCatalogLZ extends BaseApiAdapter {\n    constructor(config) {\n        super(config);\n        this.__dependentSource = true;\n    }\n\n    getURL(state, chain, fields) {\n        // This is intended to be aligned with another source- we will assume they are always ordered by position, asc\n        //  (regardless of the actual match field)\n        const build_option = state.genome_build || this.params.build;\n        validateBuildSource(this.constructor.name, build_option, null); // Source can override build- not mutually exclusive\n\n        // Most of our annotations will respect genome build before any other option.\n        //   But there can be more than one GWAS catalog version available in the same API, for the same build- an\n        //   explicit config option will always take\n        //   precedence.\n        // See: http://portaldev.sph.umich.edu/api/v1/annotation/gwascatalog/?format=objects\n        const default_source = (build_option === 'GRCh38') ? 5 : 6;  // EBI GWAS catalog\n        const source = this.params.source || default_source;\n        return `${this.url  }?format=objects&sort=pos&filter=id eq ${source} and chrom eq '${state.chr}' and pos ge ${state.start} and pos le ${state.end}`;\n    }\n\n    findMergeFields(records) {\n        // Data from previous sources is already namespaced. Find the alignment field by matching.\n        const knownFields = Object.keys(records);\n        // Note: All API endoints involved only give results for 1 chromosome at a time; match is implied\n        const posMatch = knownFields.find(function (item) {\n            return item.match(/\\b(position|pos)\\b/i);\n        });\n\n        if (!posMatch) {\n            throw new Error('Could not find data to align with GWAS catalog results');\n        }\n        return { 'pos': posMatch };\n    }\n\n    extractFields (data, fields, outnames, trans) {\n        // Skip the \"individual field extraction\" step; extraction will be handled when building chain body instead\n        return data;\n    }\n\n    combineChainBody(data, chain, fields, outnames, trans) {\n        if (!data.length) {\n            return chain.body;\n        }\n\n        //  TODO: Better reuse options in the future. This source is very specifically tied to the UM PortalDev API, where\n        //   the field name is always \"log_pvalue\". Relatively few sites will write their own gwas-catalog endpoint.\n        const decider = 'log_pvalue';\n        const decider_out = outnames[fields.indexOf(decider)];\n\n        function leftJoin(left, right, fields, outnames, trans) { // Add `fields` from `right` to `left`\n            // Add a synthetic, un-namespaced field to all matching records\n            const n_matches = left['n_catalog_matches'] || 0;\n            left['n_catalog_matches'] = n_matches + 1;\n            if (decider && left[decider_out] && left[decider_out] > right[decider]) {\n                // There may be more than one GWAS catalog entry for the same SNP. This source is intended for a 1:1\n                //  annotation scenario, so for now it only joins the catalog entry that has the best -log10 pvalue\n                return;\n            }\n\n            for (let j = 0; j < fields.length; j++) {\n                const fn = fields[j];\n                const outn = outnames[j];\n\n                let val = right[fn];\n                if (trans && trans[j]) {\n                    val = trans[j](val);\n                }\n                left[outn] = val;\n            }\n        }\n\n        const chainNames = this.findMergeFields(chain.body[0]);\n        const catNames = this.findMergeFields(data[0]);\n\n        var i = 0, j = 0;\n        while (i < chain.body.length && j < data.length) {\n            var left = chain.body[i];\n            var right = data[j];\n\n            if (left[chainNames.pos] === right[catNames.pos]) {\n                // There may be multiple catalog entries for each matching SNP; evaluate match one at a time\n                leftJoin(left, right, fields, outnames, trans);\n                j += 1;\n            } else if (left[chainNames.pos] < right[catNames.pos]) {\n                i += 1;\n            } else {\n                j += 1;\n            }\n        }\n        return chain.body;\n    }\n}\n\n/**\n * Data Source for Gene Data, as fetched from the LocusZoom/Portaldev API server (or compatible format)\n * @public\n */\nclass GeneLZ extends BaseApiAdapter {\n    getURL(state, chain, fields) {\n        const build = state.genome_build || this.params.build;\n        let source = this.params.source;\n        validateBuildSource(this.constructor.name, build, source);\n\n        if (build) {\n            // If build specified, we auto-select the best current portaldev API dataset for that build\n            // If build is not specified, we use the exact source ID provided by the user.\n            // See: https://portaldev.sph.umich.edu/api/v1/annotation/genes/sources/?format=objects\n            source = (build === 'GRCh38') ? 4 : 5;\n        }\n        return `${this.url}?filter=source in ${source} and chrom eq '${state.chr}' and start le ${state.end} and end ge ${state.start}`;\n    }\n\n    normalizeResponse(data) {\n        // Genes have a very complex internal data format. Bypass any record parsing, and provide the data layer with\n        // the exact information returned by the API. (ignoring the fields array in the layout)\n        return data;\n    }\n\n    extractFields(data, fields, outnames, trans) {\n        return data;\n    }\n}\n\n/**\n * Data Source for Gene Constraint Data, as fetched from the gnomAD server (or compatible)\n *\n * This is intended to be the second request in a chain, with special logic that connects it to Genes data\n *  already fetched.\n *\n * @public\n*/\nclass GeneConstraintLZ extends BaseApiAdapter {\n    constructor(config) {\n        super(config);\n        this.__dependentSource = true;\n    }\n    getURL() {\n        // GraphQL API: request details are encoded in the body, not the URL\n        return this.url;\n    }\n\n    normalizeResponse(data) {\n        return data;\n    }\n\n    fetchRequest(state, chain, fields) {\n        const build = state.genome_build || this.params.build;\n        if (!build) {\n            throw new Error(`Data source ${this.constructor.name} must specify a 'genome_build' option`);\n        }\n\n        const unique_gene_names = chain.body.reduce(\n            // In rare cases, the same gene symbol may appear at multiple positions. (issue #179) We de-duplicate the\n            //  gene names to avoid issuing a malformed GraphQL query.\n            function (acc, gene) {\n                acc[gene.gene_name] = null;\n                return acc;\n            },\n            {}\n        );\n        let query = Object.keys(unique_gene_names).map(function (gene_name) {\n            // GraphQL alias names must match a specific set of allowed characters: https://stackoverflow.com/a/45757065/1422268\n            const alias = `_${gene_name.replace(/[^A-Za-z0-9_]/g, '_')}`;\n            // Each gene symbol is a separate graphQL query, grouped into one request using aliases\n            return `${alias}: gene(gene_symbol: \"${gene_name}\", reference_genome: ${build}) { gnomad_constraint { exp_syn obs_syn syn_z oe_syn oe_syn_lower oe_syn_upper exp_mis obs_mis mis_z oe_mis oe_mis_lower oe_mis_upper exp_lof obs_lof pLI oe_lof oe_lof_lower oe_lof_upper } } `;\n        });\n\n        if (!query.length) {\n            // If there are no genes, skip the network request\n            return Promise.resolve({ data: null });\n        }\n\n        query = `{${query.join(' ')} }`; // GraphQL isn't quite JSON; items are separated by spaces but not commas\n        const url = this.getURL(state, chain, fields);\n        // See: https://graphql.org/learn/serving-over-http/\n        const body = JSON.stringify({ query: query });\n        const headers = { 'Content-Type': 'application/json' };\n\n        // Note: The gnomAD API sometimes fails randomly.\n        // If request blocked, return  a fake \"no data\" signal so the genes track can still render w/o constraint info\n        return fetch(url, { method: 'POST', body, headers }).then((response) => {\n            if (!response.ok) {\n                return [];\n            }\n            return response.text();\n        }).catch((err) => []);\n    }\n\n    combineChainBody(data, chain, fields, outnames, trans) {\n        if (!data) {\n            return chain;\n        }\n\n        chain.body.forEach(function(gene) {\n            // Find payload keys that match gene names in this response\n            const alias = `_${gene.gene_name.replace(/[^A-Za-z0-9_]/g, '_')}`;  // aliases are modified gene names\n            const constraint = data[alias] && data[alias]['gnomad_constraint']; // gnomad API has two ways of specifying missing data for a requested gene\n            if (constraint) {\n                // Add all fields from constraint data- do not override fields present in the gene source\n                Object.keys(constraint).forEach(function (key) {\n                    let val = constraint[key];\n                    if (typeof gene[key] === 'undefined') {\n                        if (typeof val == 'number' && val.toString().includes('.')) {\n                            val = parseFloat(val.toFixed(2));\n                        }\n                        gene[key] = val;   // These two sources are both designed to bypass namespacing\n                    }\n                });\n            }\n        });\n        return chain.body;\n    }\n}\n\n/**\n * Data Source for Recombination Rate Data, as fetched from the LocusZoom API server (or compatible)\n * @public\n */\nclass RecombLZ extends BaseApiAdapter {\n    getURL(state, chain, fields) {\n        const build = state.genome_build || this.params.build;\n        let source = this.params.source;\n        validateBuildSource(this.constructor.SOURCE_NAME, build, source);\n\n        if (build) { // If build specified, choose a known Portal API dataset IDs (build 37/38)\n            source = (build === 'GRCh38') ? 16 : 15;\n        }\n        return `${this.url}?filter=id in ${source} and chromosome eq '${state.chr}' and position le ${state.end} and position ge ${state.start}`;\n    }\n}\n\n/**\n * Data Source for static blobs of data as raw JS objects. This does not perform additional parsing, which is required\n *  for some sources (eg when joining together LD and association data).\n *\n * Therefore it is the responsibility of the user to pass information in a format that can be read and\n * understood by the chosen plot- a StaticJSON source is rarely a drop-in replacement.\n *\n * This source is largely here for legacy reasons. More often, a convenient way to serve static data is as separate\n *  JSON files to an existing source (with the JSON url in place of an API).\n * @public\n */\nclass StaticSource extends BaseAdapter {\n    parseInit(data) {\n        // Does not receive any config; the only argument is the raw data, embedded when source is created\n        this._data = data;\n    }\n    getRequest(state, chain, fields) {\n        return Promise.resolve(this._data);\n    }\n}\n\n\n/**\n * Data source for PheWAS data retrieved from a LocusZoom/PortalDev compatible API\n * @public\n * @param {String[]} init.params.build This datasource expects to be provided the name of the genome build that will\n *   be used to provide pheWAS results for this position. Note positions may not translate between builds.\n */\nclass PheWASLZ extends BaseApiAdapter {\n    getURL(state, chain, fields) {\n        const build = (state.genome_build ? [state.genome_build] : null) || this.params.build;\n        if (!build || !Array.isArray(build) || !build.length) {\n            throw new Error(['Data source', this.constructor.SOURCE_NAME, 'requires that you specify array of one or more desired genome build names'].join(' '));\n        }\n        const url = [\n            this.url,\n            \"?filter=variant eq '\", encodeURIComponent(state.variant), \"'&format=objects&\",\n            build.map(function (item) {\n                return `build=${encodeURIComponent(item)}`;\n            }).join('&'),\n        ];\n        return url.join('');\n    }\n\n    getCacheKey(state, chain, fields) {\n        // This is not a region-based source; it doesn't make sense to cache by a region\n        return this.getURL(state, chain, fields);\n    }\n}\n\n\n/**\n * Base class for \"connectors\"- this is meant to be subclassed, rather than used directly.\n *\n * A connector is a source that makes no server requests and caches no data of its own. Instead, it decides how to\n *  combine data from other sources in the chain. Connectors are useful when we want to request (or calculate) some\n *  useful piece of information once, but apply it to many different kinds of record types.\n *\n * Typically, a subclass will implement the field merging logic in `combineChainBody`.\n *\n * @public\n * @param {Object} init Configuration for this source\n * @param {Object} init.sources Specify how the hard-coded logic should find the data it relies on in the chain,\n *  as {internal_name: chain_source_id} pairs. This allows writing a reusable connector that does not need to make\n *  assumptions about what namespaces a source is using.\n * @type {*|Function}\n */\nclass ConnectorSource extends BaseAdapter {\n    constructor(config) {\n        super(config);\n\n        if (!config || !config.sources) {\n            throw new Error('Connectors must specify the data they require as init.sources = {internal_name: chain_source_id}} pairs');\n        }\n\n        /**\n         * Tells the connector how to find the data it relies on\n         *\n         * For example, a connector that applies burden test information to the genes layer might specify:\n         *  {gene_ns: \"gene\", aggregation_ns: \"aggregation\"}\n         *\n         * @member {Object}\n         */\n        this._source_name_mapping = config.sources;\n\n        // Validate that this source has been told how to find the required information\n        const specified_ids = Object.keys(config.sources);\n        /** @property {String[]} Specifies the sources that must be provided in the original config object */\n\n        this._getRequiredSources().forEach((k) => {\n            if (!specified_ids.includes(k)) {\n                // TODO: Fix constructor.name usage in minified bundles\n                throw new Error(`Configuration for ${this.constructor.name} must specify a source ID corresponding to ${k}`);\n            }\n        });\n    }\n\n    // Stub- connectors don't have their own url or data, so the defaults don't make sense\n    parseInit() {}\n\n    getRequest(state, chain, fields) {\n        // Connectors do not request their own data by definition, but they *do* depend on other sources having been loaded\n        //  first. This method performs basic validation, and preserves the accumulated body from the chain so far.\n        Object.keys(this._source_name_mapping).forEach((ns) => {\n            const chain_source_id = this._source_name_mapping[ns];\n            if (chain.discrete && !chain.discrete[chain_source_id]) {\n                throw new Error(`${this.constructor.name} cannot be used before loading required data for: ${chain_source_id}`);\n            }\n        });\n        return Promise.resolve(chain.body || []);\n    }\n\n    parseResponse(data, chain, fields, outnames, trans) {\n        // A connector source does not update chain.discrete, but it may use it. It bypasses data formatting\n        //  and field selection (both are assumed to have been done already, by the previous sources this draws from)\n\n        // Because of how the chain works, connectors are not very good at applying new transformations or namespacing.\n        // Typically connectors are called with `connector_name:all` in the fields array.\n        return Promise.resolve(this.combineChainBody(data, chain, fields, outnames, trans))\n            .then(function(new_body) {\n                return {header: chain.header || {}, discrete: chain.discrete || {}, body: new_body};\n            });\n    }\n\n    combineChainBody(records, chain) {\n        // Stub method: specifies how to combine the data\n        throw new Error('This method must be implemented in a subclass');\n    }\n\n    /**\n     * Helper method since ES6 doesn't support class fields\n     * @private\n     */\n    _getRequiredSources() {\n        throw new Error('Must specify an array that identifes the kind of data required by this source');\n    }\n}\n\nexport { BaseAdapter, BaseApiAdapter };\n\nexport {\n    AssociationLZ,\n    ConnectorSource,\n    GeneConstraintLZ,\n    GeneLZ,\n    GwasCatalogLZ,\n    LDServer,\n    PheWASLZ,\n    RecombLZ,\n    StaticSource,\n};\n","module.exports = raremetal;"],"sourceRoot":""}